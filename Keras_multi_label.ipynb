{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_multi-label.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMLqEZr0VvExAyWaXB4edHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneesh2711/Bioinformatics/blob/master/Keras_multi_label.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk-joHYscS5L"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import inf\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-VUzC2Xs0Qz",
        "outputId": "378cabc4-376d-46ba-903f-5dfcd15c7ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_fn = \"/content/drive/My Drive/Colab Notebooks/Protien_prediction/data\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNn8mvnsgYy9"
      },
      "source": [
        "branch_term = \"GO0071840\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mzsy1NiOWAI"
      },
      "source": [
        "shared_layers_num = 2\n",
        "spec_layers_num = 2\n",
        "shared_layers_units = [500,200,100]\n",
        "spec_layers_units = [100,100,100]\n",
        "dropout = [0.4,0.3,0.3]\n",
        "optimizer = 'adam'\n",
        "metrics=['accuracy']\n",
        "batch_size = 128\n",
        "oversample = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzlnJ7u7gkmr"
      },
      "source": [
        "all_data_x_fn = data_fn + '/all_data_X.csv'\n",
        "all_data_x = pd.read_csv(all_data_x_fn, sep='\\t', header=0, index_col=0)\n",
        "all_proteins_train = [p.replace('\"', '') for p in all_data_x.index]\n",
        "all_data_x.index = all_proteins_train\n",
        "\n",
        "all_data_y_fn = data_fn + '/all_data_Y.csv'\n",
        "all_data_y = pd.read_csv(all_data_y_fn, sep='\\t', header=0, index_col=0)\n",
        "all_proteins_train = [p.replace('\"', '') for p in all_data_y.index]\n",
        "all_data_y.index = all_proteins_train"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdyNKDqtjvoC"
      },
      "source": [
        "train_fn = data_fn + '/train_sets/' + branch_term + '_train.csv'\n",
        "train_y = pd.read_csv(train_fn, sep='\\t', header=0, index_col=0)\n",
        "tasks = train_y.columns\n",
        "proteins_train = [p for p in train_y.index if p in all_data_x.index]\n",
        "train_x = all_data_x.loc[proteins_train, :].values\n",
        "train_y = all_data_y.loc[proteins_train, tasks].values\n",
        "validate_fn = data_fn + '/train_sets/' + branch_term + '_valid.csv'\n",
        "validate_y = pd.read_csv(validate_fn, sep='\\t', header=0, index_col=0)\n",
        "proteins_validate = [p for p in validate_y.index if p in all_data_x.index]\n",
        "validate_x = all_data_x.loc[proteins_validate, :].values\n",
        "validate_y = all_data_y.loc[proteins_validate, tasks].values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RNXssuvIEVg"
      },
      "source": [
        "loss= ['binary_crossentropy']*len(tasks)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiLho42uuOvp"
      },
      "source": [
        "def test():\n",
        "  train_set = {}\n",
        "  validate_set = {}\n",
        "  train_labels = []\n",
        "  validation_labels = []\n",
        "  for task in tasks:\n",
        "    proteins_in_train = train_y.index[train_y.loc[:, task] != inf]\n",
        "    train_y = train_y.loc[proteins_in_train, :]\n",
        "    proteins_in_validate = validate_y.index[validate_y.loc[:, task] != inf]\n",
        "    validate_y = validate_y.loc[proteins_in_validate, :]\n",
        "  for task in tasks:\n",
        "    train_labels.append(train_y.loc[proteins_in_train,task].values)\n",
        "    validation_labels.append(validate_y.loc[proteins_in_validate,task].values)\n",
        "  train_set = [train_x.loc[proteins_in_train, :].values, train_labels]\n",
        "  validate_set = [validate_x.loc[proteins_in_validate, :].values, validation_labels]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBqczuSwQgn"
      },
      "source": [
        "shared_layers = []\n",
        "spec_layers = {}\n",
        "outputs = []\n",
        "\n",
        "inputs = Input(shape=(258,))\n",
        "x = Dropout(dropout[0])(inputs)\n",
        "for i in range(shared_layers_num):\n",
        "  name = \"shared-\"+ str(i)\n",
        "  layer = Dense(shared_layers_units[i], activation='relu',name = name)(x)\n",
        "  shared_layers.append(layer)\n",
        "  x = Dropout(dropout[1])(layer)\n",
        "for task in tasks:\n",
        "  spec_layers[task] = []\n",
        "  layer = Dense(spec_layers_units[0], activation='relu',name = task+\"-spec-0\")(x)\n",
        "  spec_layers[task].append(layer)\n",
        "  y = Dropout(dropout[2])(layer)\n",
        "  for i in range(1,spec_layers_num):\n",
        "    name = task+\"-spec-\"+ str(i)\n",
        "    layer = Dense(spec_layers_units[i], activation='relu',name = name)(y)\n",
        "    spec_layers[task].append(layer)\n",
        "    y = Dropout(dropout[2])(layer)\n",
        "  outputs.append(Dense(1, activation='sigmoid',name=task)(y))\n",
        "model = Model(inputs = inputs,outputs = outputs,name = branch_term)\n",
        "#print(model.summary())\n",
        "#plot_model(model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0VW6qElTltq"
      },
      "source": [
        "model.compile(optimizer = optimizer, loss = loss, metrics=metrics)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvxQFiRbLfjX"
      },
      "source": [
        "callback = EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDHd5CURL72p"
      },
      "source": [
        "train_yk = train_y.transpose()\n",
        "train_labels=[]\n",
        "v_yk = validate_y.transpose()\n",
        "v_labels=[]\n",
        "for i in range(len(tasks)):\n",
        "  train_labels.append(train_yk[i])\n",
        "  v_labels.append(v_yk[i])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIe-1k1fUveg",
        "outputId": "a670ba39-af9c-46e8-f208-64b190755a98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_x, train_labels, epochs = 50,batch_size=batch_size, verbose=0, validation_data = (validate_x, v_labels))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ec8b70b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Dd0eUxU9zS"
      },
      "source": [
        "for i in range(shared_layers_num):\n",
        "  name = \"shared-\"+str(i)\n",
        "  layer = model.get_layer(name)\n",
        "  if layer.trainable == True:\n",
        "    layer.trainable = False\n",
        "  assert layer.trainable == False\n",
        "model.compile(optimizer = optimizer, loss= loss, metrics=metrics)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTnskDTZWvYq",
        "outputId": "8c5e7cfb-6c7d-4644-dc5f-5209de2e963f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_x, train_labels, epochs = 50,batch_size=batch_size, verbose=0, validation_data = (validate_x, v_labels))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ec74d9550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G_zrVvMYAZP"
      },
      "source": [
        "test_fn = data_fn + '/train_sets/' + branch_term + '_test.csv'\n",
        "test_y = pd.read_csv(test_fn, sep='\\t', header=0, index_col=0)\n",
        "proteins_test = [p for p in test_y.index if p in all_data_x.index]\n",
        "test_x = all_data_x.loc[proteins_test, :].values\n",
        "test_y = all_data_y.loc[proteins_test, :].values.transpose()\n",
        "#test_set = {}\n",
        "#predict_set = {}\n",
        "#test_labels = []\n",
        "#for task in tasks:\n",
        "#  proteins_in_test = test_y.index[test_y.loc[:, task] != inf]\n",
        "#  test_y = test_y.loc[proteins_in_test, :]\n",
        "#for task in tasks:\n",
        "#  test_labels.append(test_y.loc[proteins_in_test,task].values)\n",
        "#test_set = [test_x.loc[proteins_in_test, :].values, test_labels]\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_g-My6WLTB8"
      },
      "source": [
        "predict_set = model.predict(test_x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wOzuxr5KHZc",
        "outputId": "6a62eb77-0278-4d51-af00-e72341d3114f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_labels = []\n",
        "predict_labels = []\n",
        "for i in range(len(tasks)):\n",
        "  test_labels = np.concatenate((test_labels,test_y[i]))\n",
        "  predict_l = predict_set[i].reshape(len(predict_set[i]))\n",
        "  predict_labels = np.concatenate((predict_labels,predict_l))\n",
        "\n",
        "i = 1\n",
        "Fmax = 0\n",
        "T = 0\n",
        "while i < 100:\n",
        "  k = i/100\n",
        "  predict_labels_T = (predict_labels>k)\n",
        "  f1 = f1_score(test_labels, predict_labels_T)\n",
        "  \n",
        "  if f1>Fmax:\n",
        "    Fmax = f1\n",
        "    T = i\n",
        "  i = i + 1\n",
        "print(str(Fmax) + \"---\"+ str(T))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06286076943999518---19\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}